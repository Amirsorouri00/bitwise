Goal: Translate from C to assembly language

Idea: Gradually lower C towards target language

Example:

int *p = ...;
uintptr_t n = ...;

p += n;

=> (remove pointer arithmetic)

p = (int *)((uintptr_t)p + n * sizeof(int));

=> (remove nested subexpressions)

uintptr_t t1 = n * sizeof(int);
p = (int *)((uintptr_t)p + t1);

=> (strength reduction, assuming sizeof(int) == 4)

uintptr_t t1 = n << 2;
p = (int *)((uintptr_t)p + t1);

=> (direct translation by assembly, assuming p and n are in registers)

slli t1, n, 2   // uintptr_t t1 = n << 2
add p, t1       // p = (int *)((uintptr_t)p + t1);

Features in C that may not be available in an assembly language:
- Local and global variables (vs registers, memory locations)
- Non-word-sized data types (uint8, int64, arrays, structs/unions)
- "Missing" operations (e.g. sign/zero extension)
- Pointer arithmetic (implicit multiplication and division)
- Nested/compound expressions
- Structured control flow
- Short-circuiting expressions with implicit control flow
- Functions

Local variables:

Initially assume all local variables fit in registers.
Assume the target machine only has word-sized registers (e.g. 32 bits).

Then easy to do word-sized operations that correspond 1:1 to instructions:

uint32 a = ...;
uint32 b = ...;
uint32 c = a + b;

=> (direct translation to assembly)

add c, a, b // uint32 c = a + b;

But there are still missing word-sized operations, e.g. no seq on RISC-V,

uint32 c = a == b;

=> (lower from set-if-equal to set-if-zero)

uint32 c = a - b == 0;

=> (remove nested subexpressions)

uint32 c = a - b;
c = c == 0;

=> (direct translation to assembly)

sub c, a, b // uint32 c = a - b;
seqz c      // c = c == 0;

=> (expansion of seqz pseudoinstruction)

sub c, a, b // uint32 c = a - b;
sltiu c, 1  // c = c == 0;

---

Subword locals have to live in word-sized registers and use word-sized ops.

uint8 a = ...;
uint8 b = ...;
uint8 c = a + b;

Note that C promotes a and b to ints before addition, so this is implicitly equivalent to

uint8 c = int(a) + int(b);

And int is then implicitly converted back to uint8 for the assignment/initialization:

uint8 c = uint8(int(a) + int(b));

For most operations, information flows from less significant bits to more significant bits
or don't flow at all. E.g. bitwise operations like and, or, xor don't have any flow of
information between bits, and addition and multiplication have carries from lower bits to
higher bits. This means that you can often do a long sequence of subword ops with word ops and only do word-to-subword conversion "at the end".

But in any case, this suggests that it's a good idea to avoid using anything but word-sized
arithmetic/operations. Try to treat uint8, uint16, etc, purely as storage types that are used
for memory loads/stores, and do most things with native ints, uints if possible.

Naive conversion:

uint8 a = ...;
uint8 b = ...;
uint8 c = ...;
uint8 d = uint8(int(a) + int(b));
int e = c < d;

=> (remove nested subexpressions)

int t1 = int(a) + int(b);
uint8 d = uint8(t1);
int e = c < d;

=> (direct conversion to assembly)

add d, a, b // int t1 = int(a) + int(b);
zext8 d     // d = uint8(t1);
slt e, c, d // int e = c < d;

=> (expand zext8 pseudoinstruction)

add d, a, b // int t1 = int(a) + int(b);
andi d, 255 // d = uint8(t1);
slt e, c, d // int e = c < d;

If we're using int8 rather than uint8, it would be sext8 instead of zext8,
and sext8 d would expand to

slli d, 24
srai d, 24

Keep in mind that RISC-V and other architectures, while they may not have
subword arithmetic operations, they always have subword (byte and halfword)
store-to-memory operations, in which case zero/sign extension can be elided:

static uint8 s;

uint8 a = ...;
uint8 b = ...;
s = a + b;

=> (remove nested subexpressions, assignment to static is an implicit store)

uint32 t1 = a + b;
s = t1;

=> (direct translation to assembly)

add t1, a, b // uint32 t1 = a + b;
sb s, t1     // s = t1;

Note that sb/sh/sw may be a pseudoinstruction when used with a label like s as its
destination operand, but we won't further expand it here.

---

For operations on larger-than-word-sized operands like uint64 on a 32-bit platform,
you can store each local variable in two registers and synthesize double-width
operations from single-width operations. The details vary with the architecture,
e.g. it's easier/faster to generate double-width adds if the arch has a carry flag,
so on x86 you can do

    add eax, ecx
    adc ebx, edx

for a 64-bit add, where eax:ebx is the first operand and ecx:edx is the second operand.
Here adc is "add with carry", which adds an extra 1 if the previous add had a carry.
This kind of thing has traditionally always been available, e.g. here's how you'd do
a 16-bit add on 6502, which has 8-bit operations:

    lda X
    add Y
    sta Z
    lda X+1
    adc Y+1
    sta Z+1

However, RISC-V (and a few others) chose not to have a carry flag, so it's actually
a bit more work to synthesize a double-width add on that architecture. Interestingly,
while the multiply in the M extension of RISC-V doesn't produce a double-width result,
it has a mulh/mulhu instruction that you can call to generate the higher half of the
result separately. You can synthesize a 64x64 = 64 bit multiply from 3x 32-bit mul,
2x 32-bit mulh/mulhu and 2x 32-bit add instructions.

Suppose we want to add al:ah to bl:bh where al, ah, bl, bh are 32-bit words. The
result will be stored in cl:ch.

    add cl, al, bl
    add ch, ah, bh
    sltu t1, cl, al // ch will be the carry of cl = al + bl
    add ch, t1      // add in the carry

Suppose want to to calculate c = a * b. As before, break them into 32-bit parts:

    cl + ch * 2^32 = (al + ah * 2^32) * (bl + bh * 2^32)
                   = al * bl + (al * bh + ah * bl) * 2^32 + ah * bh * 2^64

We want to calculate this mod 2^64, so the last term vanishes. And then we want to
break this into the upper and lower 32-bit halves, so

    cl = lo(al * bl)
    ch = hi(al * bl) + lo(al * bh) + lo(ah * bl)

You can calculate the lo and hi products using mul/mulh and then you have to do the
adds. You don't have to worry about carries here for the adds since only the upper
half of the result involves explicit additions, and we don't care about anything beyond
64 bits. So the code would look something like this for an unsigned 64x64 = 64 bit mul:

    mul cl, al, bl
    mulhu ch, al, bl
    mul t1, al, bh
    add ch, t1
    mul t1, ah, bl
    add ch, t1

What about 64-bit comparisons in terms of 32-bit comparisons? Equality is easy: al:ah ==
bl:bh iff al == bl and ah == bh. Depending on the context, you can implement the 'and'
with cascaded branches or bitwise and. Inequality is only a little bit trickier. We just
have to do lexicographic comparisons: al:ah < bl:bh iff ah < bh or (ah == bh and al < bl).
Again, you can implement the logic with bitwise ops or branches.

Division is quite a bit more complicated, so I won't cover that here. The M extension of
RISC-V has no provision like mulh for assisting with double-width divides.

---

Arrays are implemented via pointer arithmetic like in C, so let's cover pointer arithmetic.

If given a base pointer p, p[i] is equivalent to *(p + i) and p + i is in turn equivalent to
*(int *)((uintptr_t)p + i * sizeof(*p)). We already showed in the intro how this translates to assembly:

    int *p = ...;
    uint32 x = p[i];

=> (conversion to pointer arithmetic, removal of pointer arithmetic)

    int x = *(int *)((uintptr_t)p + i * sizeof(*p));

=> (remove nested expressions, strength reduction of * to << when sizeof(*p) == 4)

    uint32 t1 = i << 2;
    int *t2 = (int *)((uintptr_t)p + t1);
    int x = *t2;

=> (direct translation to assembly)

    slli x, i, 2
    add x, p
    lw x, [x]

Note that here (as earlier) I'm reusing registers rather than using separate temporary registers where it's clear and makes sense. I won't point that out explicitly anymore.

---

Subtraction of pointers is a little subtle. It looks innocent enough at the C level but
actually involves an implicit divide at the assembly level. For example,

    typedef struct {
        float x, y, z;
    } Vector;

    Vector *p = ...;
    Vector *q = ...;
    ptrdiff_t n = p - q;

=> (removal of pointer arithmetic)

    ptrdiff_t n = ((uintptr_t)p - (uintptr_t)q) / sizeof(Vector);

=> (naive conversion to assembly, don't do this)

    sub n, p, q
    li t1, 12
    div n, t1

Divides are still extremely high latency operations even on modern computers, so this is
pretty bad. If the division was by a power of two, it could be reduced to a right shift,
but here we're dividing by 12, so no simple optimization like that is available. However,
there is a trick used by every compiler for optimizing divisions by constants. We won't
cover that in detail here, but you can look it up.

---

Structs and unions are handled by calculating the sizes and offsets of the fields and then
doing explicit offset arithmetic when referencing fields.

    typedef struct {
        int x; // offset 0
        int y; // offset 4
        int z; // offset 8
    } Vector;

    static Vector v;

    int y = v.y;

=> (convert field access to explicit offset arithmetic)

    int y = *(int *)((uintptr_t)&v + offsetof(Vector, y));

=> (remove nested expressions)

    uintptr_t p = (uintptr_t)&v + offsetof(Vector, y);
    int y = *(int *)p;

=> (one possible translation to assembly)

    la p, v
    lw y, [p, OFFSET_VECTOR_Y]

=> (another possible translation to assembly)

    la p, v + OFFSET_VECTOR_Y
    lw y, [p]

This assumes v is a label that requires the pseudoinstruction la to load its address. OFFSET_VECTOR_Y is an assembler constant which corresponds to offsetof(Vector, y),
so it equals the constant 4 in this case.

The la pseudoinstruction will in general expand to 2 instructions: AUIPC or LUI to load the upper 20 immediate bits, and ADDI to load the lower 12 immediate bits.

While in the above case, the two possible translations take the same number of cycles,
if you're loading/storing multiple fields, you always want to exploit the load/store addressing
modes with immediate offsets:

    int x = v.x;
    int y = v.y;
    int z = v.z;

=> (go directly to assembly)

    la p, v
    lw x, [p, OFFSET_VECTOR_X]
    lw y, [p, OFFSET_VECTOR_Y]
    lw z, [p, OFFSET_VECTOR_Z]

In order to calculate offsets and sizes for structs/union fields, you have to know the ABI's packing and alignment conventions.

---

Assembly language only directly supports "unstructured" control flow with direct jumps to a location, indirect jumps (where the target is provided in a register), and conditional branches. How do you translate C-style structured control flow with if, while, for, etc into
that vocabulary?

if without else:

    if (x) {
        // A
    }
    // B

=>

    if (!x) goto B_start;
    // A
    B_start:
    // B

if with else:

    if (x) {
        // A
    } else {
        // B
    }
    // C

=>

    if (!x) goto B_start;
    // A
    goto C_start;
    B_start:
    // B
    C_start:
    // C

do-while loop:

    do {
        // A
    } while (x);
    // B

=>

    A_start:
    // A
    A_continue:
    if (x) goto A_start;
    A_break:
    // B

If there is a break or continue in the scope of the do-while loop, they act as
gotos to the A_break or A_continue labels.

Rather than formulating while loops directly in terms of unstructured control flow,
you can see them as a variant of do-while loops:

    while (x) {
        // A
    }
    // B

=>

    goto A_continue;
    do {
        // A
        A_continue:
    } while (x);
    // B

=>

    goto A_continue;
    A_start:
    // A
    A_continue:
    if (x) goto A_start;
    A_break:
    // B

Now we can directly translate any of the unstructured C snippets to assembly code:

    goto A_continue;
    A_start:
    // A
    A_continue:
    if (x) goto A_start;
    A_break:
    // B

=>

    jmp A_continue
    A_start:
    // A
    A_continue:
    bne x, 0, A_start
    // B

Or if you want to use local shorthand labels:

    jmp 2>
1:  // A
2:  bne x, 0, <1
    // B

Here we were assuming the condition was based on the zeroness or nonzeroness of a variable x.
In general, that is sufficient to support any condition. You can reduce a compound logical
condition to something that generates a value into a variable x that can then be used with
beq or bne. However, you should exploit the fused compare-and-branch instructions that RISC-V offers.

Don't do this:

    if (x < y) {
        // A
    }
    // B

=> (remove expression from if condition)

    int t1 = x < y;
    if (t1) {
        // A
    }
    // B

=> (direct translation to assembly)

    slt t1, x, y
    beq t1, 0, >1
    // A
1:  // B

Do this instead:

    if (x < y) {
        // A
    }
    // B

=> (reduction to unstructured control flow)

    if (x >= y) goto B_start;
    // A
    B_start:
    // B

=> (direct translation to assembly)

    bge x, y, B_start
    // A
    B_start:
    // B

Short-circuiting conditional expressions are translated to control flow.

Logical and:

    if (/* A */ && /* B */) {
        // C
    }
    // D

=>

    if (!(/* A */)) goto D_start;
    if (!(/* B */)) goto D_start;
    // C
    D_start:
    // D

Logical or:

    if (/* A */ || /* B */) {
        // C
    }
    // D

=>

    if (/* A */) goto C_start;
    if (/* B */) goto C_start;
    goto D_start;
    C_start:
    // C
    // D

